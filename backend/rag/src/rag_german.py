
from haystack.components.retrievers.in_memory import InMemoryBM25Retriever, InMemoryEmbeddingRetriever
from haystack.components.embedders import OpenAITextEmbedder
from document_handler import DocumentStoreHandler
from haystack.components.joiners import DocumentJoiner
from haystack.components.rankers import TransformersSimilarityRanker
from haystack_integrations.components.generators.llama_cpp import LlamaCppGenerator
from haystack import Pipeline
from haystack.components.builders.answer_builder import AnswerBuilder
from haystack.components.builders import PromptBuilder
from dotenv import load_dotenv
load_dotenv()

# The `RAG` class initializes a Retrieval-Augmented Generation (RAG) model for question answering,
# incorporating components for document retrieval, text embedding, answer generation, and prompt
# building.
class RAG:
    def __init__(self, model_path="backend/rag/models/llama-2-13b.Q4_K_M.gguf") -> None:
        self.doc_store_handler = DocumentStoreHandler('backend/rag/data')
        self.doc_store_handler.write_docs2docstore()

        self.document_store = self.doc_store_handler.document_store
        self.text_embedder = OpenAITextEmbedder(model="text-embedding-3-large")
        self.build_hybrid_retrieval()
        # Load the LLM using LlamaCppGenerator
        self.generator = LlamaCppGenerator(model=model_path, n_ctx=4096, n_batch=128)
        self.build_rag()
        print('RAG initialised')

    def build_rag(self):
        '''The `build_rag` function in Python sets up a pipeline for a RAG (Retrieval-Augmented Generation)
        model by adding components and connecting them together.
        
        '''
        self.rag_pipeline = self.retrieval
        self.build_prompt()

        self.rag_pipeline.add_component(instance=self.prompt_builder, name="prompt_builder")
        self.rag_pipeline.add_component(instance=self.generator, name="llm")
        self.rag_pipeline.add_component(instance=AnswerBuilder(), name="answer_builder")
        
        self.rag_pipeline.connect("embedding_retriever", "prompt_builder.documents")
        self.rag_pipeline.connect("prompt_builder", "llm")
        self.rag_pipeline.connect("llm.replies", "answer_builder.replies")
        #self.rag_pipeline.connect("ranker.documents", "answer_builder.documents")


    def build_hybrid_retrieval(self):
        '''The function `build_hybrid_retrieval` sets up a pipeline for hybrid document retrieval using
        embedding and BM25 retrievers.
        
        '''
        self.embedding_retriever = InMemoryEmbeddingRetriever(self.document_store)
        self.bm25_retriever = InMemoryBM25Retriever(self.document_store)
        self.document_joiner = DocumentJoiner(join_mode="concatenate")
        #self.ranker = TransformersSimilarityRanker(model="BAAI/bge-reranker-large")
        #self.ranker.warm_up()
        
        self.retrieval = Pipeline()
        self.retrieval.add_component("text_embedder", self.text_embedder)
        self.retrieval.add_component("embedding_retriever", self.embedding_retriever)
        #self.retrieval.add_component("bm25_retriever", self.bm25_retriever)
        
        #self.retrieval.add_component("document_joiner", self.document_joiner)
        #self.retrieval.add_component("ranker", self.ranker)

        self.retrieval.connect("text_embedder", "embedding_retriever.query_embedding")
        #self.retrieval.connect("bm25_retriever", "document_joiner")
        #self.retrieval.connect("embedding_retriever", "document_joiner")
        #self.retrieval.connect("document_joiner", "ranker")

    def visualize_retrieval(self): 
        '''The function `visualize_retrieval` saves a visualization of retrieval results to a file named
        "retrieval.png".
        
        '''
        self.retrieval.draw("retrieval.png")

    def run_retrieval(self, query:str):
        '''This function takes a query as input, runs retrieval using different methods, and returns the
        result from the ranker.
        
        Parameters
        ----------
        query : str
            The `run_retrieval` method takes a query string as input and runs a retrieval process using
        different components such as a text embedder, a BM25 retriever, and a ranker. The query string
        is used as input for each of these components to retrieve relevant information.
        
        Returns
        -------
            The code snippet is returning the result from the "ranker" component after running retrieval
        with the given query.
        
        '''
        result = self.retrieval.run(
            {"text_embedder": {"text": query}, 
             "bm25_retriever": {"query": query}, 
             "ranker": {"query": query}}
             )
        return result["ranker"]
    
    def run(self, query:str): 
        '''The `run` function takes a query as input, processes it through various components in a
        pipeline, and returns the answers generated by the pipeline.
        
        Parameters
        ----------
        query : str
            The `run` method takes a `query` parameter as input, which is a string representing the text
        for which you want to generate answers. The method then runs a pipeline that processes this
        query through various components such as text embedder, prompt builder, llm (language model),
        and answer builder
        
        Returns
        -------
            The function `run` takes a query as input and runs a pipeline that processes the query using
        various components such as text embedder, prompt builder, llm, and answer builder. The function
        then returns the answers generated by the answer builder component.
        
        '''
        result = self.rag_pipeline.run(
            {
                "text_embedder": {"text": query},
                #"bm25_retriever": {"query": query}, 
                #"ranker": {"query": query},
                "prompt_builder": {"question": query},
                "llm": {"generation_kwargs": {"max_tokens": 128, "temperature": 0.1}},
                "answer_builder": {"query": query},
            }
        )
        return result["answer_builder"]["answers"]
    
    def build_prompt(self):
        '''The `build_prompt` function defines a template for generating prompts for a German teacher to
        answer questions from students, incorporating information from provided documents when relevant.
        '''
        template = """
Du bist ein Deutschlehrer. Antworte auf die Fragen von deinen Schülern. 
Wenn die Frage kein Bezug zur deutschen Sprache hat, schreib: 'Ich kann keine Antwort geben'.
Benutze Information unten, um die Frage, wenn die Frage über Deutsch ist, zu beantworten. 
{% for document in documents %}
    {{ document.content }}
{% endfor %}

Question: {{question}}
Answer:
"""
        self.prompt_builder = PromptBuilder(template=template)
    

    


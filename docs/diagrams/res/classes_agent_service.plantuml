@startuml classes_agent_service
set namespaceSeparator none
class "<color:red>ActionInputNotFoundException</color>" as agent_service.exeptions.step_exception.ActionInputNotFoundException {
}
class "<color:red>ActionNotFoundException</color>" as agent_service.exeptions.step_exception.ActionNotFoundException {
}
class "Agent" as agent_service.agent.agent.Agent {
  config
  llm
  max_iterations : FieldInfo
  prompt_builder
  reasoning_logger
  step_parser
  task_type
  tool_executor
  trajectory_injector
  validation_parser
  add_trajectory_examples_to_prompts(query) -> None
  execute_step(step: AgentStep) -> None
  get_current_prompt(mode) -> str
  get_final_response(iteration: int) -> str
  init_prompts(task_type: TaskType)
  parse_config() -> None
  plan_step() -> AgentStep
  process_validation_thought(val_answer: str) -> bool
  reset()
  run(query: str) -> str
  take_step() -> bool
  update_prompts_for_query(query: str) -> None
  validate() -> bool
}
class "AgentConfigModel" as agent_service.core.pydantic_agent.AgentConfigModel {
  llm : str
  max_iterations : int
}
class "AgentFinalStep" as agent_service.agent.agent_step.AgentFinalStep {
  final_answer : str
}
class "AgentMode" as agent_service.agent.agent.AgentMode {
  name
}
class "AgentStep" as agent_service.agent.agent_step.AgentStep {
  action : str
  action_input : str
  observation : Optional[str]
  thought : str
}
class "AgentValidationStep" as agent_service.agent.agent_step.AgentValidationStep {
  validation_thought : str
}
class "BedrockLLMConfigModel" as agent_service.core.pydantic_llm.BedrockLLMConfigModel {
  accept : str
  content_type : str
  llm_id : str
  max_tokens : int
  region_name : str
  service_name : str
  temperature : float
}
class "ColoredFormatter" as agent_service.core.log.ColoredFormatter {
  COLORS : dict
  format(record)
}
class "Config" as agent_service.core.config.Config {
  DIR
  class_name
  config : ConfigParser
  filename : bytes, str
  get_settings()
  load_config()
  set_llm(task_type)
  update_llm(llm: str)
}
class "ExercisesParser" as agent_service.agent.exercises_parser.ExercisesParser {
  parse() -> Dict[str, str]
}
class "<color:red>ExtractingExercisesError</color>" as agent_service.tools.task_generation_tool.TaskGenerator.ExtractingExercisesError {
}
class "<color:red>InvalidToolException</color>" as agent_service.exeptions.step_exception.InvalidToolException {
}
class "LLM" as agent_service.agent.llm.LLM {
  max_tokens : int
  {abstract}run()
  set_max_tokens(max_tokens: int)
  set_max_tokens_by_mode(mode)
}
class "LLMBedrock" as agent_service.agent.llm.LLMBedrock {
  client : 
  config
  llm_id
  max_tokens : FieldInfo, int
  get_body(prompt: str)
  parse_config()
  run(prompt: str, mode)
  set_max_tokens(max_tokens: int)
}
class "LLMRunPod" as agent_service.agent.llm.LLMRunPod {
  config
  llm_id
  max_tokens : FieldInfo
  temperature : FieldInfo
  url
  parse_config()
  run(prompt: str, mode)
}
class "ListeningGenerator" as agent_service.tools.listening_generation_tool.ListeningGenerator {
  PROMPT_ID : str
  TEMPLATE : str
  description : str
  name : str
  prompt
  query
  run(input: str)
}
class "NoAnswerTool" as agent_service.tools.no_answer_tool.NoAnswerTool {
  description : str
  name : str
  run(input_str: str)
}
class "Parser" as agent_service.parsers.agent_step_parser.Parser {
  {abstract}parse_step(input: str)
}
class "PhrasingTool" as agent_service.tools.phrasing_tool.PhrasingTool {
  PROMPT_ID : str
  TEMPLATE : str
  description : str
  name : str
  prompt
  query
  run(input_str: str)
}
class "Prompt" as agent_service.prompts.prompt_builder.Prompt {
  name
  prompt
}
class "PromptBuilder" as agent_service.prompts.prompt_builder.PromptBuilder {
  create_prompts(prompt_dict: dict)
  generate_prompt(name_id) -> str
  get_prompt(name)
  set_prompt(name, prompt: str)
  update_prompt(name_id) -> str
}
class "ReadingGenerator" as agent_service.tools.reading_generation_tool.ReadingGenerator {
  PROMPT_ID : str
  TEMPLATE : str
  description : str
  name : str
  prompt
  query
  run(input: str)
}
class "ReasoningLogger" as agent_service.agent.reasoning_trace.ReasoningLogger {
  errors : List[Exception]
  final_answer
  model_id : Optional[str]
  query : NoneType, str
  query_id : NoneType, str
  task_type
  trace : List[Union[AgentStep, AgentValidationStep, AgentFinalStep]]
  add_exception(e: Exception)
  add_step(step: Union[AgentStep, AgentValidationStep, AgentFinalStep])
  build_final_answer()
  get_last_step() -> Union[AgentStep, AgentValidationStep, AgentFinalStep]
  remove_step(index: int) -> None
  set_query(query: str)
  set_query_id(query_id: str)
  to_json()
}
class "RetrievalTool" as agent_service.tools.retrieval_tool.RetrievalTool {
  COLLECTION_NAME : str
  DB_PATH : str
  DOC_PATH : str
  PROMPT_ID : str
  ROOT_PATH : str
  TEMPLATE : str
  client : MilvusClient
  collection : NoneType
  description : str
  ef
  list_docs : list
  list_src : list
  min_chunk_len : int
  name : str
  prompt
  query
  add_docs()
  get_src_chunks(text: str)
  parse_info(markdown_text_list)
  parse_retrieval_results(results: Dict) -> str
  read_markdown_folder(folder_path)
  run(input: str) -> str
  start_vector_store(init)
}
class "RunpodLLMConfigModel" as agent_service.core.pydantic_llm.RunpodLLMConfigModel {
  llm_id : str
  max_tokens : int
  temperature : float
}
class "StepParser" as agent_service.parsers.agent_step_parser.StepParser {
  logger : NoneType, RootLogger
  tool_names : List[str]
  extract_action(remaining_text)
  extract_thought(first_line)
  find_tool(action)
  parse_step(input: str) -> AgentStep
  remove_quotes(input)
  validate_action(action, action_input)
}
class "TaskGenerator" as agent_service.tools.task_generation_tool.TaskGenerator {
  PROMPT_ID : str
  TEMPLATE : str
  description : str
  dir_path : str
  name : str
  prompt
  build_prompts(input: Dict[str, str])
  extract_exercises(message: str, exercises_num: int) -> str
  parse_input(input: str) -> Dict[str, str]
  run(input: str)
  save_exercises(exercises: str)
}
class "TaskType" as agent_service.agent.task_type.TaskType {
  name
}
class "Tool" as agent_service.tools.tool.Tool {
  llm
  {abstract}run(input: str)
  set_llm(llm)
}
class "ToolExecutor" as agent_service.tools.tool_executor.ToolExecutor {
  config
  factory
  logger : NoneType, RootLogger
  reasoning_logger
  task_type
  tool_names : List[str]
  tools : List[Tool]
  add_trace_for_task_generation(tool_name, input)
  execute(tool_name: str, input_str: str) -> str
  get_tool_by_name(name: str) -> Tool
  parse_config(task_type: TaskType)
}
class "ToolExecutorConfigModel" as agent_service.core.pydantic_tool_exe.ToolExecutorConfigModel {
  listening_generator : bool
  llm : str
  no_answer : bool
  phrasing_tool : bool
  reading_generator : bool
  retriever : bool
  task_generator : bool
  translator : bool
  web_search : bool
}
class "ToolFactory" as agent_service.tools.tool_factory.ToolFactory {
  config
  tool_map : dict
  tool_names : list
  tools : list
  initialize_tools()
}
class "TrajectoryInjector" as agent_service.prompts.trajectory_library.TrajectoryInjector {
  COLLECTION_NAME : str
  DB_PATH : str
  DOC_PATH : str
  ROOT_PATH : str
  client : MilvusClient
  collection : NoneType
  df_docs : DataFrame
  ef
  add_docs()
  inject_trajectories(query: str, top_k) -> Tuple[str, str]
  parse_doc(doc: str, metadata: Dict) -> Tuple[str, str]
  parse_examples(results: Dict) -> Tuple[str, str]
  parse_trajectories(markdown_text_list)
  read_markdown_folder(folder_path)
  start_vector_store(init)
}
class "Translator" as agent_service.tools.translator_tool.Translator {
  PROMPT_ID : str
  TEMPLATE : str
  description : str
  name : str
  prompt
  translator : Translator
  parse_target_language(input)
  run(input: str) -> str
  set_target_language(lang: str) -> None
}
class "ValidationParser" as agent_service.parsers.agent_step_parser.ValidationParser {
  logger : NoneType, RootLogger
  parse_step(input: str) -> AgentValidationStep
}
class "WebSearch" as agent_service.tools.web_search_tool.WebSearch {
  PROMPT_ID : str
  TEMPLATE : str
  api_host : str
  api_key
  description : str
  name : str
  prompt
  query
  url : str
  parse_results(results)
  run(input_str: str)
  setup_request(input: str)
}
agent_service.agent.llm.LLMBedrock --|> agent_service.agent.llm.LLM
agent_service.agent.llm.LLMRunPod --|> agent_service.agent.llm.LLM
agent_service.parsers.agent_step_parser.StepParser --|> agent_service.parsers.agent_step_parser.Parser
agent_service.parsers.agent_step_parser.ValidationParser --|> agent_service.parsers.agent_step_parser.Parser
agent_service.tools.listening_generation_tool.ListeningGenerator --|> agent_service.tools.tool.Tool
agent_service.tools.no_answer_tool.NoAnswerTool --|> agent_service.tools.tool.Tool
agent_service.tools.phrasing_tool.PhrasingTool --|> agent_service.tools.tool.Tool
agent_service.tools.reading_generation_tool.ReadingGenerator --|> agent_service.tools.tool.Tool
agent_service.tools.retrieval_tool.RetrievalTool --|> agent_service.tools.tool.Tool
agent_service.tools.task_generation_tool.TaskGenerator --|> agent_service.tools.tool.Tool
agent_service.tools.translator_tool.Translator --|> agent_service.tools.tool.Tool
agent_service.tools.web_search_tool.WebSearch --|> agent_service.tools.tool.Tool
agent_service.agent.llm.LLMBedrock --* agent_service.agent.agent.Agent : llm
agent_service.agent.llm.LLMBedrock --* agent_service.tools.tool.Tool : llm
agent_service.agent.llm.LLMRunPod --* agent_service.agent.agent.Agent : llm
agent_service.agent.llm.LLMRunPod --* agent_service.tools.tool.Tool : llm
agent_service.agent.reasoning_trace.ReasoningLogger --* agent_service.agent.agent.Agent : reasoning_logger
agent_service.agent.reasoning_trace.ReasoningLogger --* agent_service.agent.agent.Agent : reasoning_logger
agent_service.core.pydantic_agent.AgentConfigModel --* agent_service.agent.agent.Agent : config
agent_service.core.pydantic_llm.BedrockLLMConfigModel --* agent_service.agent.llm.LLMBedrock : config
agent_service.core.pydantic_llm.RunpodLLMConfigModel --* agent_service.agent.llm.LLMRunPod : config
agent_service.core.pydantic_tool_exe.ToolExecutorConfigModel --* agent_service.tools.tool_executor.ToolExecutor : config
agent_service.parsers.agent_step_parser.StepParser --* agent_service.agent.agent.Agent : step_parser
agent_service.parsers.agent_step_parser.ValidationParser --* agent_service.agent.agent.Agent : validation_parser
agent_service.prompts.prompt_builder.PromptBuilder --* agent_service.agent.agent.Agent : prompt_builder
agent_service.prompts.prompt_builder.PromptBuilder --* agent_service.tools.listening_generation_tool.ListeningGenerator : prompt
agent_service.prompts.prompt_builder.PromptBuilder --* agent_service.tools.phrasing_tool.PhrasingTool : prompt
agent_service.prompts.prompt_builder.PromptBuilder --* agent_service.tools.reading_generation_tool.ReadingGenerator : prompt
agent_service.prompts.prompt_builder.PromptBuilder --* agent_service.tools.retrieval_tool.RetrievalTool : prompt
agent_service.prompts.prompt_builder.PromptBuilder --* agent_service.tools.task_generation_tool.TaskGenerator : prompt
agent_service.prompts.prompt_builder.PromptBuilder --* agent_service.tools.translator_tool.Translator : prompt
agent_service.prompts.prompt_builder.PromptBuilder --* agent_service.tools.web_search_tool.WebSearch : prompt
agent_service.prompts.trajectory_library.TrajectoryInjector --* agent_service.agent.agent.Agent : trajectory_injector
agent_service.tools.tool_executor.ToolExecutor --* agent_service.agent.agent.Agent : tool_executor
agent_service.tools.tool_factory.ToolFactory --* agent_service.tools.tool_executor.ToolExecutor : factory
agent_service.agent.reasoning_trace.ReasoningLogger --o agent_service.tools.tool_executor.ToolExecutor : reasoning_logger
agent_service.agent.task_type.TaskType --o agent_service.agent.agent.Agent : task_type
agent_service.agent.task_type.TaskType --o agent_service.tools.tool_executor.ToolExecutor : task_type
@enduml
